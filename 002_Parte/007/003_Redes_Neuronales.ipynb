{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FacuML/NLP/blob/main/002_Parte/007/003_Redes_Neuronales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas necesarias\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "yj7kF9J45hzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPxjobg15Hsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "692f382c-a343-4865-afdb-2a1cdbd52e82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo 'text_dataset.csv' creado con éxito.\n"
          ]
        }
      ],
      "source": [
        "# Crear un conjunto de datos sintético y guardarlo como CSV\n",
        "# Ejemplos de texto y etiquetas\n",
        "data = {\n",
        "    \"texto\": [\n",
        "        \"Me gusta el fútbol\",\n",
        "        \"El clima es hermoso hoy\",\n",
        "        \"No me gusta la lluvia\",\n",
        "        \"El café es delicioso\",\n",
        "        \"Prefiero té que café\",\n",
        "        \"La comida argentina es increíble\",\n",
        "        \"Amo la música\",\n",
        "        \"Los días soleados son los mejores\",\n",
        "        \"La lectura es un buen pasatiempo\",\n",
        "        \"Me gusta aprender cosas nuevas\",\n",
        "        \"No me gusta caminar bajo el sol\",\n",
        "        \"La playa estaba limpia, pero el día estaba frio\",\n",
        "        \"La comida estaba rica, pero fria\",\n",
        "    ],\n",
        "    \"etiquetas\": [\n",
        "        1,  # Positiva\n",
        "        1,  # Positiva\n",
        "        0,  # Negativa\n",
        "        1,  # Positiva\n",
        "        1,  # Positiva\n",
        "        1,  # Positiva\n",
        "        1,  # Positiva\n",
        "        1,  # Positiva\n",
        "        1,  # Positiva\n",
        "        1,  # Positiva\n",
        "        0,  # Negativa\n",
        "        0,  # Negativa\n",
        "        0,  # Negativa\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Convertir a DataFrame\n",
        "datos = pd.DataFrame(data)\n",
        "\n",
        "# Guardar como CSV\n",
        "datos.to_csv(\"text_dataset.csv\", index=False)\n",
        "\n",
        "print(\"Archivo 'text_dataset.csv' creado con éxito.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el conjunto de datos de texto\n",
        "datos = pd.read_csv(\"text_dataset.csv\")"
      ],
      "metadata": {
        "id": "WwvHF_Nm5tWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenización del texto\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(datos[\"texto\"])\n",
        "secuencias = tokenizer.texts_to_sequences(datos[\"texto\"])\n",
        "maxlen = 10  # Longitud máxima de las secuencias\n",
        "X = pad_sequences(secuencias, maxlen=maxlen)\n",
        "y = datos[\"etiquetas\"].values"
      ],
      "metadata": {
        "id": "wTZ7P-b85zbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambiar el modelo a uno adecuado para texto\n",
        "modelo = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=5000, output_dim=64, input_length=maxlen),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid')  # Cambiar según el caso de uso\n",
        "])"
      ],
      "metadata": {
        "id": "Lx3iMaBf51X_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92509a52-3bac-4ccd-ee4b-a7c2eb3f007e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilación del modelo\n",
        "modelo.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "O7UihT4C53Pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo\n",
        "entrenamiento = modelo.fit(X, y, epochs=15, batch_size=2)"
      ],
      "metadata": {
        "id": "xbd0twWW5404",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c6eae5-a255-453e-acf2-b3c4d8e5c775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5393 - loss: 0.6902\n",
            "Epoch 2/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7116 - loss: 0.6690 \n",
            "Epoch 3/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7663 - loss: 0.6468\n",
            "Epoch 4/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8933 - loss: 0.6070 \n",
            "Epoch 5/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8006 - loss: 0.5983 \n",
            "Epoch 6/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9090 - loss: 0.5792 \n",
            "Epoch 7/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8600 - loss: 0.5519 \n",
            "Epoch 8/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6256 - loss: 0.6124     \n",
            "Epoch 9/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6361 - loss: 0.6128     \n",
            "Epoch 10/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6881 - loss: 0.5654 \n",
            "Epoch 11/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6600 - loss: 0.5501 \n",
            "Epoch 12/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7819 - loss: 0.4816 \n",
            "Epoch 13/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6392 - loss: 0.5714 \n",
            "Epoch 14/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7819 - loss: 0.4589 \n",
            "Epoch 15/15\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8340 - loss: 0.4178 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicción con ejemplo de texto\n",
        "texto_ejemplo = \"El café es delicioso, pero estaba frio\"\n",
        "secuencia_ejemplo = tokenizer.texts_to_sequences([texto_ejemplo])\n",
        "secuencia_ejemplo = pad_sequences(secuencia_ejemplo, maxlen=maxlen)\n",
        "prediccion = modelo.predict(secuencia_ejemplo)\n",
        "print(f\"Predicción para el texto '{texto_ejemplo}': {prediccion[0]}\")"
      ],
      "metadata": {
        "id": "5FuKBr-u5xs6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e55583-f053-4cbd-a53f-4c1a49db835b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "Predicción para el texto 'El café es delicioso, pero estaba frio': [0.6345003]\n"
          ]
        }
      ]
    }
  ]
}